{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzpbL2znMdR1",
        "outputId": "a8a246c7-2e98-4390-caf7-125695d33d4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_P2Y6ykLag7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Configuration\n",
        "class Config:\n",
        "    SR = 32000\n",
        "    N_MELS = 128\n",
        "    N_MFCC = 13\n",
        "    MAX_SEQ_LEN = 200\n",
        "    ROOT_FOLDER = '/content/drive/MyDrive/dataset/TeamDeepwave/dataset/open/'\n",
        "    SUBSET_SIZE = 5000\n",
        "    OUTPUT_FOLDER = '/content/drive/MyDrive/dataset/TeamDeepwave/dataset/preprocessed/'\n",
        "    BATCH_SIZE = 64\n",
        "    N_EPOCHS = 10\n",
        "    LR = 1e-4\n",
        "\n",
        "CONFIG = Config()\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# Custom Dataset\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, mfcc_files, mel_files, labels=None, transform=None):\n",
        "        self.mfcc_files = mfcc_files\n",
        "        self.mel_files = mel_files\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.mel_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        mel_image = Image.open(self.mel_files[idx]).convert('L')  # Convert to grayscale\n",
        "        if self.transform:\n",
        "            mel_image = self.transform(mel_image)\n",
        "\n",
        "        if self.labels is not None:\n",
        "            label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "            mfcc = torch.zeros((CONFIG.N_MFCC, CONFIG.MAX_SEQ_LEN))\n",
        "            return mfcc, mel_image, label\n",
        "        return mel_image\n",
        "\n",
        "# Load train file paths and labels\n",
        "def load_train_file_paths_and_labels(csv_path, subset_size=CONFIG.SUBSET_SIZE):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    df_subset = df.sample(n=subset_size)\n",
        "    file_paths = df_subset['path'].apply(lambda x: os.path.join(CONFIG.ROOT_FOLDER, x)).tolist()\n",
        "    labels = df_subset['label'].tolist()\n",
        "    return file_paths, labels\n",
        "\n",
        "# Load test file paths\n",
        "def load_test_file_paths(csv_path, subset_size=CONFIG.SUBSET_SIZE):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    df_subset = df.sample(n=subset_size)\n",
        "    file_paths = df_subset['path'].apply(lambda x: os.path.join(CONFIG.ROOT_FOLDER, x)).tolist()\n",
        "    return file_paths\n",
        "\n",
        "# Define the Bi-LSTM model\n",
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
        "        super(BiLSTM, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, bidirectional=bidirectional, dropout=dropout, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)  # hidden_dim * 2 because it's bidirectional\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        num_directions = 2 if self.lstm.bidirectional else 1\n",
        "        h_0 = torch.zeros(self.lstm.num_layers * num_directions, x.size(0), self.lstm.hidden_size).to(device)\n",
        "        c_0 = torch.zeros(self.lstm.num_layers * num_directions, x.size(0), self.lstm.hidden_size).to(device)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "        lstm_out, _ = self.lstm(x, (h_0, c_0))\n",
        "        x = self.fc(self.dropout(lstm_out[:, -1, :]))\n",
        "        return x\n",
        "\n",
        "# Define the CNN model for Mel-spectrogram images\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, output_dim):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.fc1 = nn.Linear(64 * 32 * 32, 128)\n",
        "        self.fc2 = nn.Linear(128, output_dim)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.gelu(self.conv1(x)))  # Replace F.relu with F.gelu\n",
        "        x = self.pool(F.gelu(self.conv2(x)))  # Replace F.relu with F.gelu\n",
        "        x = x.view(-1, 64 * 32 * 32)\n",
        "        x = F.gelu(self.fc1(x))  # Replace F.relu with F.gelu\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Combine both models\n",
        "class CombinedModel(nn.Module):\n",
        "    def __init__(self, lstm_input_dim, lstm_hidden_dim, lstm_output_dim, lstm_n_layers, lstm_bidirectional, lstm_dropout, cnn_output_dim):\n",
        "        super(CombinedModel, self).__init__()\n",
        "        self.lstm = BiLSTM(lstm_input_dim, lstm_hidden_dim, lstm_output_dim, lstm_n_layers, lstm_bidirectional, lstm_dropout)\n",
        "        self.cnn = CNN(cnn_output_dim)\n",
        "        self.fc = nn.Linear(lstm_output_dim + cnn_output_dim, 2)\n",
        "\n",
        "    def forward(self, mfcc, mel):\n",
        "        lstm_out = torch.zeros(mfcc.size(0), 128).to(device)  # Dummy LSTM output if no MFCC is provided\n",
        "        if mfcc is not None:\n",
        "            mfcc = mfcc.permute(0, 2, 1)  # Change from (batch, channels, seq_len) to (batch, seq_len, input_dim)\n",
        "            lstm_out = self.lstm(mfcc)\n",
        "        cnn_out = self.cnn(mel)\n",
        "        combined = torch.cat((lstm_out, cnn_out), dim=1)\n",
        "        out = self.fc(combined)\n",
        "        return out\n",
        "\n",
        "# Training and validation functions\n",
        "def train(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for mfcc, mel, labels in loader:\n",
        "        mfcc, mel, labels = mfcc.to(device), mel.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(mfcc, mel)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        _, labels = torch.max(labels.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    accuracy = correct / total if total > 0 else 0  # Avoid division by zero\n",
        "    return epoch_loss / len(loader) if len(loader) > 0 else 0, accuracy\n",
        "\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for mfcc, mel, labels in loader:\n",
        "            mfcc, mel, labels = mfcc.to(device), mel.to(device), labels.to(device)\n",
        "            outputs = model(mfcc, mel)\n",
        "            loss = criterion(outputs, labels)\n",
        "            epoch_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            _, labels = torch.max(labels.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = correct / total if total > 0 else 0  # Avoid division by zero\n",
        "    return epoch_loss / len(loader) if len(loader) > 0 else 0, accuracy\n",
        "\n",
        "# Main training loop\n",
        "def main():\n",
        "    # Load train data\n",
        "    train_files, train_labels = load_train_file_paths_and_labels('/content/drive/MyDrive/dataset/TeamDeepwave/dataset/open/train.csv')\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((128, 128)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5], std=[0.5])  # Grayscale normalization\n",
        "    ])\n",
        "\n",
        "    train_dataset = CustomDataset(train_files, train_files, train_labels, transform=transform)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=CONFIG.BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    # Model initialization\n",
        "    model = CombinedModel(\n",
        "        lstm_input_dim=CONFIG.N_MFCC,\n",
        "        lstm_hidden_dim=128,\n",
        "        lstm_output_dim=128,\n",
        "        lstm_n_layers=2,\n",
        "        lstm_bidirectional=True,\n",
        "        lstm_dropout=0.5,\n",
        "        cnn_output_dim=128\n",
        "    ).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=CONFIG.LR)\n",
        "\n",
        "    # Training loop\n",
        "    best_valid_loss = float('inf')\n",
        "    for epoch in range(CONFIG.N_EPOCHS):\n",
        "        train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
        "        # Assuming you have validation data and loader (val_loader)\n",
        "        # valid_loss, valid_acc = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "        # if valid_loss < best_valid_loss:\n",
        "        #     best_valid_loss = valid_loss\n",
        "        #     torch.save(model.state_dict(), 'best-model.pt')\n",
        "\n",
        "        print(f'Epoch {epoch+1}')\n",
        "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "        # print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "\n",
        "    # Save the model weights in .h5 format\n",
        "    model_path = 'model_weights.h5'\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    print(f'Model weights saved to {model_path}')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}